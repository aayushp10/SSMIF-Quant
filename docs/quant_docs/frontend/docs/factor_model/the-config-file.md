---
id: the-config-file
title: The Config File
sidebar_label: The Config File
slug: /the-config-file
---
### Developers
- [Michael DiGregorio](https://www.linkedin.com/in/michael-jonathan-digregorio/)

### What is a Config File and Why Do We Use It?

#### You can find an example of a real config file (don't worry about the finance, these are valid placeholder values) [here](example-config)

A config file is what we use to store a model configuration. In english, a config file outlines all of the inputs and parameters of a certain configuration of the Factor Model
The config file currently contains the following fields and subfields:
    - project
        - data
            - window
            - bloomberg
            - additional
            - operations
        - models
        - predict
    - optimization

## Project
A project is a 'unit' that we are building a predictive model for. For example, a project can be used to represent a financial sector, individual equity, or a collection of equities, as long as the intended result of the prediction is a single time series output

In the Factor Model's base-case, we have one project per financial sector we invest in

Importantly, one project makes up a single 'asset' in the final optimization, and the output of the prediction for that project is it's corresponding input to optimization

## Data
The data field is really just an organizational grouping of all of the fields related to our data processing pipeline: 
- [window](#window)
- [bloomberg](#bloomberg)
- [additional](#additional)
- [operations](#operations)

#### Additionally, you can check out our guide to the "Models" section [here](#models)

### Window
The window field has two inputs: start_date, and end_date. These correspond to the start and end dates that we will use to load the data, i.e they lay out the window we are loading data for example: 

```yaml
window:
    start_date: 2020-01-01
    end_date: 2020-11-01
```

### Bloomberg
The first of the more complicated fields, bloomberg represents all of the data we will load from, you guessed it, the Bloomberg API
Each entry of bloomberg is organized like so:

```yaml
bloomberg:
    TickerName1:
        output_basename: NULL # really this is just an alternative name for the basename of the output filepath for the data ( all data which is loaded is saved to disk )
        cols: # The columns you wish to load from the ticker specified above, these are called 'Fields' in Bloomberg lingo
            - and
            - it 
            - is 
            - a
            - list
            - PX_LAST # this is a real bloomberg field for the last price
        col_map: # can either be populated, like it is here, or empty list []
            - old_key: PX_LAST # the original column name
            new_key: new_column_name # what you want to rename the column to
            - old_key: and
            new_key: not_and
    XLK US Equity: # real bloomberg name for XLK
        ... # the ellipses are me not wanting to write out entirely new example, you can just follow the format above to load data from a different bloomberg source / ticker
    TickerName3:
        ...
```
### Additional
The additional field is most probably going to be a little-used field. The purpose of the additional field is to allow the user to load data from external sources to the model. For example, lets say that you downloaded a .csv file containing interesting data from the internet, you would load it into the model using the additional field. You would then be able to refer to columns within that data as you would any other column from a dataset the model loaded in. You are also able to distinguish between loading it as train or test data.

```yaml
additional:
    test_data:                # specify that the data below is marked as testing data
    input_path: path.csv    # a literal input path relative to the root directory of the Factor Model
    cols:                   # names of columns you want to load as they appear in the csv
        - PX_LAST
        - my_column
    col_map:                # col map to rename columns in the csv to the value in "new_key". This is exactly the same as the field of the same name from the bloomberg section
        - old_key: PX_LAST 
        new_key: target
        - old_key: my_column
        - new_key: my_column_but_renamed
```
### Operations
The third of the more compliated fields is operations. This is a data subfield. 
In operations, you will define a set of python functions to run on your data. For example, should you wish to take the ratio of column 1 and column 2, you can invoke the operation "take_ratio" as seen below.
Importantly, we rename columns to signify that they were generated by an operation. The column name is prepended with "op::" and made lower case
- Note: all columns are renamed internally, but you do not need to worry about that in the config file, everything can be referred to by the name it was loaded as in the config file

```yaml
operations:         # op::pe/px_to_sales_ratio 
    - output_columns:
        - PE/PX_TO_SALES_RATIO
    operation: take_ratio     # name of the python function
    input_columns:            # list of input columns
        - source: bloomberg     # refers to the source used to load the data, in this case, bloomberg. This may also be additional or some other field which isn't written as of today
        ticker: S5INFT Index  # the name of the ticker that the data is from. This is so that you can refer to two columns with the same name, but for different tickers 
        col_name: PE_RATIO    # the actual name of the column
        - source: bloomberg
        ticker: S5INFT Index
        col_name: PX_TO_SALES_RATIO
```

#### To learn how to make new operations functions and how operations functions work, see the guide [here](operations-functions)

## Models
The next field is the models field. This is where we will be storing the name of the models we are using, along with the necessary parameters and hyperparameters for each of these models. 

Each model will take in a name, type, predictors, window override, and hyperparameters. The name and type are essentially what type of model you are going to be using for the training and predictions. The predictors are the fields that will be used in order to predict the target. Window override specifices a start and end date for the models to use data from. Lastly, the hyperparameters are specific to each model type you use. These are meant to be adjusted to your liking in order to tune the output of your model.

```yaml
models:
    - name: LinearRegression    #name of the model
    type: linear_regression     #type of model you are using
    predictors:                 #refers to the values we are using in order to predict the target
        - source: bloomberg     #defined as the source you are getting the specified predictor data from
        ticker: S5INFT Index    #ticker of the data
        col_name: PX_TO_BOOK_RATIO      #name of the column from the data
        - source: bloomberg
        ticker: S5INFT Index
        col_name: TOT_DEBT_TO_TOT_ASSET
    window_override:            #this is where you can specify where you when you want the models to train from
        start_date: 2020-01-01  #dates are formatted as follows yyyy-mm-dd
        end_date: 2020-05-05
    hyperparams:            #specify the individual hyperparams for each given model type. This is going to vary based on each model. Foe
        fit_intercept: True     
        normalize: False
        n_jobs: -1
    - name: RandomForest
    type: random_forest
    predictors:
        - source: bloomberg
        ticker: S5INDU Index # BB_XLK_PUT_CALL_OPEN_INTEREST_RATIO
        col_name: PX_TO_BOOK_RATIO
    window_override: 
        start_date: 2020-01-01
        end_date: 2020-05-05
    hyperparams:
        n_estimators: 500
        criterion: mse
        max_depth: 5
        min_samples_split: 5
        random_state: 42
        bootstrap: True
    - name: ArimaRegression
    type: arima_regression
    window_override: 
        start_date: 2020-01-01
        end_date: 2020-05-05
    hyperparams:
        order: [5, 1, 0]
    fitparams:
        cov_type: robust
```
The documentation for the hyperparameters for each of these models can be found on the following links:
- [Arima Regression Hyperparameters](https://www.statsmodels.org/stable/generated/-statsmodels.tsa.arima.model.ARIMA.html)
- [Linear Regression Hyperparameters](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)
- [Random Forest Regression Hyperparameters](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)

For example, as you can see